{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception Model without DataAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre trained Xception weight \n",
    "# RGB Image \n",
    "# The original size of the image for the pretrained Xception model is 224x224 (224x224x3) \n",
    "# The size of our input image is resized to 128x128 (128x128x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Input\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image \n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading data\n",
    "Intially the datas are structured to input to the convolutional layer by converting the images in to numpy array, normalized (changing the range of pixel intensity values) and reshaped accordingly. Finally, stored in the path shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (11878, 5, 128, 128, 3) y_train.shape: (11878, 9)\n",
      "x_valid.shape: (1858, 5, 128, 128, 3) y_valid.shape: (1858, 9)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('/cai_lab/thomas/DWD/Numpy_RGB_Sequence_128/train/x_data_all.npy')\n",
    "y_train = np.load('/cai_lab/thomas/DWD/Numpy_RGB_Sequence_128/train/y_data_all.npy')\n",
    "\n",
    "x_valid = np.load('/cai_lab/thomas/DWD/Numpy_RGB_Sequence_128/valid/x_data_all.npy')\n",
    "y_valid = np.load('/cai_lab/thomas/DWD/Numpy_RGB_Sequence_128/valid/y_data_all.npy')\n",
    "\n",
    "print('x_train.shape:',x_train.shape,'y_train.shape:',y_train.shape)\n",
    "print('x_valid.shape:',x_valid.shape,'y_valid.shape:',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "resize = 128     # The image is resized to 128\n",
    "n_class = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0511 03:18:48.476632 140122739902208 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 23s 0us/step\n",
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "inputs = Input (shape = (resize, resize, 3))\n",
    "\n",
    "xception_conv = Xception(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "xception_conv.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5, 128, 128, 3)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 2048)           20861480  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               2360320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 25,068,081\n",
      "Trainable params: 25,011,505\n",
      "Non-trainable params: 56,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_xception = xception_conv(inputs)\n",
    "\n",
    "x=GlobalAveragePooling2D()(output_xception)\n",
    "\n",
    "\n",
    "dense_layer = Dense(1024, activation = 'relu')(x)\n",
    "dense_layer = Dropout(0.5)(dense_layer)\n",
    "dense_layer = Dense(1024, activation = 'relu')(dense_layer)\n",
    "dense_layer = BatchNormalization()(dense_layer)\n",
    "dense_layer = Dropout(0.5)(dense_layer)\n",
    "dense_layer = Dense(512, activation = 'relu')(dense_layer)\n",
    "\n",
    "\n",
    "final_output = Dense(n_class, activation = 'softmax')(dense_layer)\n",
    "\n",
    "\n",
    "final_model = Model ([inputs], final_output)\n",
    "\n",
    "final_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving and Compling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0511 03:19:27.303833 140122739902208 deprecation.py:323] From /home/cai/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0511 03:19:37.936196 140122739902208 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0511 03:19:37.955370 140122739902208 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0511 03:19:37.956166 140122739902208 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11878 samples, validate on 1858 samples\n",
      "Epoch 1/60\n",
      "11878/11878 [==============================] - 331s 28ms/step - loss: 2.0912 - accuracy: 0.2394 - val_loss: 1.8551 - val_accuracy: 0.4290\n",
      "\n",
      "Epoch 00001: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0001.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0511 03:25:33.196466 140122739902208 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "11878/11878 [==============================] - 314s 26ms/step - loss: 1.3391 - accuracy: 0.5465 - val_loss: 1.4519 - val_accuracy: 0.4903\n",
      "\n",
      "Epoch 00002: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0002.h5\n",
      "Epoch 3/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.7016 - accuracy: 0.7825 - val_loss: 1.3467 - val_accuracy: 0.5484\n",
      "\n",
      "Epoch 00003: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0003.h5\n",
      "Epoch 4/60\n",
      "11878/11878 [==============================] - 314s 26ms/step - loss: 0.3916 - accuracy: 0.8854 - val_loss: 1.4117 - val_accuracy: 0.5662\n",
      "\n",
      "Epoch 00004: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0004.h5\n",
      "Epoch 5/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.2511 - accuracy: 0.9290 - val_loss: 1.4383 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00005: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0005.h5\n",
      "Epoch 6/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.1733 - accuracy: 0.9536 - val_loss: 1.4601 - val_accuracy: 0.5829\n",
      "\n",
      "Epoch 00006: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0006.h5\n",
      "Epoch 7/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.1291 - accuracy: 0.9638 - val_loss: 1.4756 - val_accuracy: 0.5813\n",
      "\n",
      "Epoch 00007: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0007.h5\n",
      "Epoch 8/60\n",
      "11878/11878 [==============================] - 316s 27ms/step - loss: 0.0986 - accuracy: 0.9764 - val_loss: 1.4876 - val_accuracy: 0.5910\n",
      "\n",
      "Epoch 00008: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0008.h5\n",
      "Epoch 9/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.0827 - accuracy: 0.9792 - val_loss: 1.4091 - val_accuracy: 0.6168\n",
      "\n",
      "Epoch 00009: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0009.h5\n",
      "Epoch 10/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.0676 - accuracy: 0.9830 - val_loss: 1.3877 - val_accuracy: 0.6254\n",
      "\n",
      "Epoch 00010: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0010.h5\n",
      "Epoch 11/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0591 - accuracy: 0.9854 - val_loss: 1.5460 - val_accuracy: 0.5953\n",
      "\n",
      "Epoch 00011: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0011.h5\n",
      "Epoch 12/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0536 - accuracy: 0.9856 - val_loss: 1.6022 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00012: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0012.h5\n",
      "Epoch 13/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0474 - accuracy: 0.9871 - val_loss: 1.4587 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00013: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0013.h5\n",
      "Epoch 14/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0419 - accuracy: 0.9901 - val_loss: 1.5129 - val_accuracy: 0.6163\n",
      "\n",
      "Epoch 00014: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0014.h5\n",
      "Epoch 15/60\n",
      "11878/11878 [==============================] - 322s 27ms/step - loss: 0.0374 - accuracy: 0.9913 - val_loss: 1.4765 - val_accuracy: 0.6211\n",
      "\n",
      "Epoch 00015: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0015.h5\n",
      "Epoch 16/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 1.4608 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00016: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0016.h5\n",
      "Epoch 17/60\n",
      "11878/11878 [==============================] - 322s 27ms/step - loss: 0.0298 - accuracy: 0.9928 - val_loss: 1.4919 - val_accuracy: 0.6233\n",
      "\n",
      "Epoch 00017: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0017.h5\n",
      "Epoch 18/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0280 - accuracy: 0.9941 - val_loss: 1.4027 - val_accuracy: 0.6389\n",
      "\n",
      "Epoch 00018: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0018.h5\n",
      "Epoch 19/60\n",
      "11878/11878 [==============================] - 322s 27ms/step - loss: 0.0237 - accuracy: 0.9947 - val_loss: 1.5352 - val_accuracy: 0.6206\n",
      "\n",
      "Epoch 00019: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0019.h5\n",
      "Epoch 20/60\n",
      "11878/11878 [==============================] - 325s 27ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 1.5049 - val_accuracy: 0.6346\n",
      "\n",
      "Epoch 00020: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0020.h5\n",
      "Epoch 21/60\n",
      "11878/11878 [==============================] - 315s 27ms/step - loss: 0.0214 - accuracy: 0.9954 - val_loss: 1.5509 - val_accuracy: 0.6281\n",
      "\n",
      "Epoch 00021: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0021.h5\n",
      "Epoch 22/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 1.6199 - val_accuracy: 0.6195\n",
      "\n",
      "Epoch 00022: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0022.h5\n",
      "Epoch 23/60\n",
      "11878/11878 [==============================] - 323s 27ms/step - loss: 0.0189 - accuracy: 0.9954 - val_loss: 1.5443 - val_accuracy: 0.6276\n",
      "\n",
      "Epoch 00023: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0023.h5\n",
      "Epoch 24/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 1.5389 - val_accuracy: 0.6319\n",
      "\n",
      "Epoch 00024: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0024.h5\n",
      "Epoch 25/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 1.5078 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00025: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0025.h5\n",
      "Epoch 26/60\n",
      "11878/11878 [==============================] - 328s 28ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 1.5081 - val_accuracy: 0.6335\n",
      "\n",
      "Epoch 00026: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0026.h5\n",
      "Epoch 27/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 1.5614 - val_accuracy: 0.6313\n",
      "\n",
      "Epoch 00027: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0027.h5\n",
      "Epoch 28/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 1.5684 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00028: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0028.h5\n",
      "Epoch 29/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 1.5308 - val_accuracy: 0.6346\n",
      "\n",
      "Epoch 00029: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0029.h5\n",
      "Epoch 30/60\n",
      "11878/11878 [==============================] - 318s 27ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 1.5511 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00030: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0030.h5\n",
      "Epoch 31/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 1.5128 - val_accuracy: 0.6249\n",
      "\n",
      "Epoch 00031: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0031.h5\n",
      "Epoch 32/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 1.5356 - val_accuracy: 0.6281\n",
      "\n",
      "Epoch 00032: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0032.h5\n",
      "Epoch 33/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 1.3803 - val_accuracy: 0.6523\n",
      "\n",
      "Epoch 00033: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0033.h5\n",
      "Epoch 34/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 1.5146 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00034: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0034.h5\n",
      "Epoch 35/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 1.5229 - val_accuracy: 0.6346\n",
      "\n",
      "Epoch 00035: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0035.h5\n",
      "Epoch 36/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 1.5220 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00036: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0036.h5\n",
      "Epoch 37/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 1.5441 - val_accuracy: 0.6351\n",
      "\n",
      "Epoch 00037: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0037.h5\n",
      "Epoch 38/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 1.4965 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00038: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0038.h5\n",
      "Epoch 39/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 1.5877 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00039: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0039.h5\n",
      "Epoch 40/60\n",
      "11878/11878 [==============================] - 322s 27ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 1.5471 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00040: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0040.h5\n",
      "Epoch 41/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 1.6371 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00041: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0041.h5\n",
      "Epoch 42/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.5925 - val_accuracy: 0.6351\n",
      "\n",
      "Epoch 00042: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0042.h5\n",
      "Epoch 43/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 1.6227 - val_accuracy: 0.6351\n",
      "\n",
      "Epoch 00043: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0043.h5\n",
      "Epoch 44/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.5063 - val_accuracy: 0.6518\n",
      "\n",
      "Epoch 00044: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0044.h5\n",
      "Epoch 45/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 1.5900 - val_accuracy: 0.6416\n",
      "\n",
      "Epoch 00045: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0045.h5\n",
      "Epoch 46/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 1.6169 - val_accuracy: 0.6356\n",
      "\n",
      "Epoch 00046: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0046.h5\n",
      "Epoch 47/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 1.5725 - val_accuracy: 0.6448\n",
      "\n",
      "Epoch 00047: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0047.h5\n",
      "Epoch 48/60\n",
      "11878/11878 [==============================] - 318s 27ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.5730 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00048: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0048.h5\n",
      "Epoch 49/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 1.6375 - val_accuracy: 0.6297\n",
      "\n",
      "Epoch 00049: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0049.h5\n",
      "Epoch 50/60\n",
      "11878/11878 [==============================] - 317s 27ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 1.5810 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00050: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0050.h5\n",
      "Epoch 51/60\n",
      "11878/11878 [==============================] - 326s 27ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 1.5906 - val_accuracy: 0.6378\n",
      "\n",
      "Epoch 00051: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0051.h5\n",
      "Epoch 52/60\n",
      "11878/11878 [==============================] - 324s 27ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 1.6116 - val_accuracy: 0.6394\n",
      "\n",
      "Epoch 00052: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0052.h5\n",
      "Epoch 53/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 1.5923 - val_accuracy: 0.6421\n",
      "\n",
      "Epoch 00053: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0053.h5\n",
      "Epoch 54/60\n",
      "11878/11878 [==============================] - 321s 27ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 1.5641 - val_accuracy: 0.6399\n",
      "\n",
      "Epoch 00054: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0054.h5\n",
      "Epoch 55/60\n",
      "11878/11878 [==============================] - 320s 27ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 1.5841 - val_accuracy: 0.6459\n",
      "\n",
      "Epoch 00055: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0055.h5\n",
      "Epoch 56/60\n",
      "11878/11878 [==============================] - 314s 26ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.5182 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00056: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0056.h5\n",
      "Epoch 57/60\n",
      "11878/11878 [==============================] - 318s 27ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.7064 - val_accuracy: 0.6249\n",
      "\n",
      "Epoch 00057: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0057.h5\n",
      "Epoch 58/60\n",
      "11878/11878 [==============================] - 318s 27ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.6754 - val_accuracy: 0.6351\n",
      "\n",
      "Epoch 00058: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0058.h5\n",
      "Epoch 59/60\n",
      "11878/11878 [==============================] - 319s 27ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 1.6369 - val_accuracy: 0.6372\n",
      "\n",
      "Epoch 00059: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0059.h5\n",
      "Epoch 60/60\n",
      "11878/11878 [==============================] - 328s 28ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 1.6334 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00060: saving model to ./checkpoints/RGB_128_Xception_and_LSTM/checkpoint-0060.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_name = 'Comp_Xception_RGB_128'\n",
    "save_path = './checkpoints/' + save_name\n",
    "\n",
    "if os.path.exists(save_path)==False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_path +'/checkpoint-{epoch:04d}.h5', verbose=1, monitor='val_loss', save_best_only=False, mode='auto', period=1)\n",
    "tensorboard = TensorBoard(log_dir='./graph/'+ save_name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "callback_list = [checkpoint, tensorboard]\n",
    "\n",
    "final_model = multi_gpu_model(final_model, gpus=2)\n",
    "\n",
    "# aug = ImageDataGenerator(\n",
    "#         rotation_range=20,\n",
    "#         zoom_range=0.15,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         shear_range=0.15,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "# Compiling\n",
    "sgd = optimizers.SGD(lr = 0.001)\n",
    "\n",
    "final_model.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "final_model.fit(x_train, y_train, \n",
    "                     batch_size=batch_size,\n",
    "                    validation_data=(x_valid, y_valid),       \n",
    "                    epochs=60,\n",
    "                    verbose=1,\n",
    "                    callbacks=callback_list)\n",
    "\n",
    "final_model.save(save_path + '/epoch-finish.h5')\n",
    "final_model.save_weights(save_path +'/epoch-finish_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
