{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 with DataAugmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vgg16\n",
    "#RGB Images\n",
    "# 128X128 resized images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Input\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image \n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading data\n",
    "Intially the datas are structured to input to the convolutional layer by converting the images in to numpy array, normalized (changing the range of pixel intensity values) and reshaped accordingly. Finally, stored in the path shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (17194, 128, 128, 3) y_train.shape: (17194, 9)\n",
      "x_valid.shape: (2558, 128, 128, 3) y_valid.shape: (2558, 9)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('/cai_lab/thomas/DWD/RGB_128_3Channel_Dataset/train/x_data_all.npy')\n",
    "y_train = np.load('/cai_lab/thomas/DWD/RGB_128_3Channel_Dataset/train/y_data_all.npy')\n",
    "\n",
    "x_valid = np.load('/cai_lab/thomas/DWD/RGB_128_3Channel_Dataset/valid/x_data_all.npy')\n",
    "y_valid = np.load('/cai_lab/thomas/DWD/RGB_128_3Channel_Dataset/valid/y_data_all.npy')\n",
    "\n",
    "print('x_train.shape:',x_train.shape,'y_train.shape:',y_train.shape)\n",
    "print('x_valid.shape:',x_valid.shape,'y_valid.shape:',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24   # The batch size is set to 32 which is different with RGB_224 \n",
    "resize = 128     # The image is reduced to 128x128 which is different with RGB_224\n",
    "n_class = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0522 01:44:14.220958 140713366554368 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "\n",
    "inputs = Input (shape = (resize, resize, 3))\n",
    "\n",
    "\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 16,823,113\n",
      "Trainable params: 16,821,065\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_vgg16 = model_vgg16_conv(inputs)\n",
    "\n",
    "\n",
    "\n",
    "x=GlobalAveragePooling2D()(output_vgg16)\n",
    "\n",
    "dense_layer = Dense(1024, activation = 'relu')(x)\n",
    "dense_layer = Dropout(0.5)(dense_layer)\n",
    "dense_layer = Dense(1024, activation = 'relu')(dense_layer)\n",
    "dense_layer = BatchNormalization()(dense_layer)\n",
    "dense_layer = Dropout(0.5)(dense_layer)\n",
    "dense_layer = Dense(512, activation = 'relu')(dense_layer)\n",
    "\n",
    "final_output = Dense(n_class, activation = 'softmax')(dense_layer)\n",
    "\n",
    "\n",
    "final_model = Model ([inputs], final_output)\n",
    "\n",
    "final_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving and compling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0522 01:44:18.486603 140713366554368 deprecation.py:323] From /home/cai/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0522 01:44:20.255704 140713366554368 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0522 01:44:20.263372 140713366554368 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0522 01:44:20.264061 140713366554368 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17194 samples, validate on 2558 samples\n",
      "Epoch 1/60\n",
      "17194/17194 [==============================] - 54s 3ms/step - loss: 2.6452 - accuracy: 0.1524 - val_loss: 1.9397 - val_accuracy: 0.3049\n",
      "\n",
      "Epoch 00001: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0001.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0522 01:45:26.993912 140713366554368 deprecation_wrapper.py:119] From /home/cai/.local/lib/python3.5/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 2.0655 - accuracy: 0.2832 - val_loss: 1.5925 - val_accuracy: 0.4433\n",
      "\n",
      "Epoch 00002: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0002.h5\n",
      "Epoch 3/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 1.6514 - accuracy: 0.4201 - val_loss: 1.3540 - val_accuracy: 0.6388\n",
      "\n",
      "Epoch 00003: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0003.h5\n",
      "Epoch 4/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 1.3154 - accuracy: 0.5511 - val_loss: 1.1107 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00004: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0004.h5\n",
      "Epoch 5/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 1.0667 - accuracy: 0.6502 - val_loss: 0.9940 - val_accuracy: 0.7275\n",
      "\n",
      "Epoch 00005: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0005.h5\n",
      "Epoch 6/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.8506 - accuracy: 0.7330 - val_loss: 0.8999 - val_accuracy: 0.7506\n",
      "\n",
      "Epoch 00006: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0006.h5\n",
      "Epoch 7/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.7045 - accuracy: 0.7814 - val_loss: 0.8711 - val_accuracy: 0.7424\n",
      "\n",
      "Epoch 00007: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0007.h5\n",
      "Epoch 8/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.5949 - accuracy: 0.8222 - val_loss: 0.8290 - val_accuracy: 0.7494\n",
      "\n",
      "Epoch 00008: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0008.h5\n",
      "Epoch 9/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.5023 - accuracy: 0.8547 - val_loss: 0.8017 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00009: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0009.h5\n",
      "Epoch 10/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.4322 - accuracy: 0.8822 - val_loss: 0.8152 - val_accuracy: 0.7537\n",
      "\n",
      "Epoch 00010: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0010.h5\n",
      "Epoch 11/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.3794 - accuracy: 0.8960 - val_loss: 0.6711 - val_accuracy: 0.7901\n",
      "\n",
      "Epoch 00011: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0011.h5\n",
      "Epoch 12/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.3376 - accuracy: 0.9093 - val_loss: 0.7756 - val_accuracy: 0.7518\n",
      "\n",
      "Epoch 00012: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0012.h5\n",
      "Epoch 13/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.3041 - accuracy: 0.9203 - val_loss: 0.7346 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00013: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0013.h5\n",
      "Epoch 14/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.2683 - accuracy: 0.9304 - val_loss: 0.6868 - val_accuracy: 0.7854\n",
      "\n",
      "Epoch 00014: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0014.h5\n",
      "Epoch 15/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.2416 - accuracy: 0.9396 - val_loss: 0.7055 - val_accuracy: 0.7823\n",
      "\n",
      "Epoch 00015: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0015.h5\n",
      "Epoch 16/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.2259 - accuracy: 0.9418 - val_loss: 0.7006 - val_accuracy: 0.7651\n",
      "\n",
      "Epoch 00016: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0016.h5\n",
      "Epoch 17/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.2047 - accuracy: 0.9491 - val_loss: 0.6966 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00017: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0017.h5\n",
      "Epoch 18/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1845 - accuracy: 0.9561 - val_loss: 0.6598 - val_accuracy: 0.7811\n",
      "\n",
      "Epoch 00018: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0018.h5\n",
      "Epoch 19/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1669 - accuracy: 0.9593 - val_loss: 0.7158 - val_accuracy: 0.7666\n",
      "\n",
      "Epoch 00019: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0019.h5\n",
      "Epoch 20/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1517 - accuracy: 0.9630 - val_loss: 0.7143 - val_accuracy: 0.7455\n",
      "\n",
      "Epoch 00020: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0020.h5\n",
      "Epoch 21/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1453 - accuracy: 0.9660 - val_loss: 0.7762 - val_accuracy: 0.7682\n",
      "\n",
      "Epoch 00021: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0021.h5\n",
      "Epoch 22/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1384 - accuracy: 0.9673 - val_loss: 0.6239 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00022: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0022.h5\n",
      "Epoch 23/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1233 - accuracy: 0.9712 - val_loss: 0.7365 - val_accuracy: 0.7768\n",
      "\n",
      "Epoch 00023: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0023.h5\n",
      "Epoch 24/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1216 - accuracy: 0.9712 - val_loss: 0.7554 - val_accuracy: 0.7783\n",
      "\n",
      "Epoch 00024: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0024.h5\n",
      "Epoch 25/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1092 - accuracy: 0.9753 - val_loss: 0.6924 - val_accuracy: 0.7881\n",
      "\n",
      "Epoch 00025: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0025.h5\n",
      "Epoch 26/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.1046 - accuracy: 0.9759 - val_loss: 0.7404 - val_accuracy: 0.7783\n",
      "\n",
      "Epoch 00026: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0026.h5\n",
      "Epoch 27/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0956 - accuracy: 0.9790 - val_loss: 0.6372 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00027: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0027.h5\n",
      "Epoch 28/60\n",
      "17194/17194 [==============================] - 49s 3ms/step - loss: 0.0930 - accuracy: 0.9802 - val_loss: 0.6576 - val_accuracy: 0.7885\n",
      "\n",
      "Epoch 00028: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0028.h5\n",
      "Epoch 29/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0879 - accuracy: 0.9813 - val_loss: 0.6728 - val_accuracy: 0.7893\n",
      "\n",
      "Epoch 00029: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0029.h5\n",
      "Epoch 30/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0789 - accuracy: 0.9833 - val_loss: 0.6972 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00030: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0030.h5\n",
      "Epoch 31/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0771 - accuracy: 0.9830 - val_loss: 0.6497 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00031: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0031.h5\n",
      "Epoch 32/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0725 - accuracy: 0.9849 - val_loss: 0.7036 - val_accuracy: 0.7967\n",
      "\n",
      "Epoch 00032: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0032.h5\n",
      "Epoch 33/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0677 - accuracy: 0.9866 - val_loss: 0.6965 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00033: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0033.h5\n",
      "Epoch 34/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0680 - accuracy: 0.9859 - val_loss: 0.6646 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00034: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0034.h5\n",
      "Epoch 35/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0648 - accuracy: 0.9865 - val_loss: 0.6377 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00035: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0035.h5\n",
      "Epoch 36/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0599 - accuracy: 0.9878 - val_loss: 0.7557 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00036: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0036.h5\n",
      "Epoch 37/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0573 - accuracy: 0.9890 - val_loss: 0.6896 - val_accuracy: 0.7924\n",
      "\n",
      "Epoch 00037: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0037.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0580 - accuracy: 0.9881 - val_loss: 0.6240 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00038: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0038.h5\n",
      "Epoch 39/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0508 - accuracy: 0.9912 - val_loss: 0.7062 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00039: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0039.h5\n",
      "Epoch 40/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0511 - accuracy: 0.9903 - val_loss: 0.6872 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00040: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0040.h5\n",
      "Epoch 41/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0525 - accuracy: 0.9891 - val_loss: 0.7297 - val_accuracy: 0.7920\n",
      "\n",
      "Epoch 00041: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0041.h5\n",
      "Epoch 42/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0474 - accuracy: 0.9909 - val_loss: 0.7477 - val_accuracy: 0.7756\n",
      "\n",
      "Epoch 00042: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0042.h5\n",
      "Epoch 43/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0458 - accuracy: 0.9915 - val_loss: 0.6698 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00043: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0043.h5\n",
      "Epoch 44/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0457 - accuracy: 0.9913 - val_loss: 0.7032 - val_accuracy: 0.7885\n",
      "\n",
      "Epoch 00044: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0044.h5\n",
      "Epoch 45/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0422 - accuracy: 0.9926 - val_loss: 0.7437 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00045: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0045.h5\n",
      "Epoch 46/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0389 - accuracy: 0.9934 - val_loss: 0.7529 - val_accuracy: 0.7803\n",
      "\n",
      "Epoch 00046: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0046.h5\n",
      "Epoch 47/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0398 - accuracy: 0.9926 - val_loss: 0.7174 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00047: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0047.h5\n",
      "Epoch 48/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0382 - accuracy: 0.9933 - val_loss: 0.6865 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00048: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0048.h5\n",
      "Epoch 49/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0368 - accuracy: 0.9936 - val_loss: 0.7375 - val_accuracy: 0.7862\n",
      "\n",
      "Epoch 00049: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0049.h5\n",
      "Epoch 50/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0369 - accuracy: 0.9942 - val_loss: 0.8089 - val_accuracy: 0.7768\n",
      "\n",
      "Epoch 00050: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0050.h5\n",
      "Epoch 51/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0349 - accuracy: 0.9933 - val_loss: 0.6736 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00051: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0051.h5\n",
      "Epoch 52/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0326 - accuracy: 0.9942 - val_loss: 0.7164 - val_accuracy: 0.7920\n",
      "\n",
      "Epoch 00052: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0052.h5\n",
      "Epoch 53/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0339 - accuracy: 0.9942 - val_loss: 0.7202 - val_accuracy: 0.7842\n",
      "\n",
      "Epoch 00053: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0053.h5\n",
      "Epoch 54/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0314 - accuracy: 0.9948 - val_loss: 0.7439 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00054: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0054.h5\n",
      "Epoch 55/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.6372 - val_accuracy: 0.7873\n",
      "\n",
      "Epoch 00055: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0055.h5\n",
      "Epoch 56/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.6252 - val_accuracy: 0.7971\n",
      "\n",
      "Epoch 00056: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0056.h5\n",
      "Epoch 57/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0288 - accuracy: 0.9951 - val_loss: 0.6724 - val_accuracy: 0.7924\n",
      "\n",
      "Epoch 00057: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0057.h5\n",
      "Epoch 58/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0258 - accuracy: 0.9967 - val_loss: 0.6707 - val_accuracy: 0.7991\n",
      "\n",
      "Epoch 00058: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0058.h5\n",
      "Epoch 59/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0268 - accuracy: 0.9952 - val_loss: 0.7334 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00059: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0059.h5\n",
      "Epoch 60/60\n",
      "17194/17194 [==============================] - 48s 3ms/step - loss: 0.0261 - accuracy: 0.9958 - val_loss: 0.7395 - val_accuracy: 0.7905\n",
      "\n",
      "Epoch 00060: saving model to ./checkpoints/Comp_VGG16_RGB_128/checkpoint-0060.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_name = 'Comp_VGG16_RGB_128_Ag'   \n",
    "save_path = './checkpoints/' + save_name   # saved path \n",
    "\n",
    "if os.path.exists(save_path)==False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_path +'/checkpoint-{epoch:04d}.h5', verbose=1, monitor='val_loss', save_best_only=False, mode='auto', period=1)\n",
    "tensorboard = TensorBoard(log_dir='./graph/'+ save_name, histogram_freq=0, write_graph=True, write_images=True)\n",
    "callback_list = [checkpoint, tensorboard]\n",
    "\n",
    "final_model = multi_gpu_model(final_model, gpus=2)\n",
    "\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.001)  \n",
    "\n",
    "final_model.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    \n",
    "final_model.fit(x_train, y_train, \n",
    "                     batch_size=batch_size,\n",
    "                    validation_data=(x_valid, y_valid),       \n",
    "                    epochs=60,\n",
    "                    verbose=1,\n",
    "                    callbacks=callback_list)\n",
    "\n",
    "final_model.save(save_path + '/epoch-finish.h5')\n",
    "final_model.save_weights(save_path +'/epoch-finish_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
